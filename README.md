# Ainux OS - AI Cluster Operating System

<div align="center">

![Ainux OS Logo](https://img.shields.io/badge/Ainux%20OS-AI%20Cluster%20OS-00FF88?style=for-the-badge&logo=linux)

[![Build Status](https://img.shields.io/badge/Build-Passing-success?style=flat-square)](https://github.com/yaotagroep/ainux/actions)
[![Kernel](https://img.shields.io/badge/Kernel-6.6.58%20LTS-blue?style=flat-square)](https://kernel.org)
[![License](https://img.shields.io/badge/License-MIT-green?style=flat-square)](https://github.com/yaotagroep/ainux/blob/main/LICENSE.md)
[![Release](https://img.shields.io/github/v/release/yaotagroep/ainux?style=flat-square)](https://github.com/yaotagroep/ainux/releases)

*A specialized Linux distribution optimized for AI workloads and cluster computing*

[ğŸš€ Quick Start](#quick-start) â€¢ [ğŸ“– Documentation](#documentation) â€¢ [ğŸ’» Installation](#installation) â€¢ [ğŸ¤ Contributing](#contributing) â€¢ [ğŸ“‹ Roadmap](#roadmap)

</div>

---

## ğŸ¯ Overview

**Ainux OS** is a purpose-built Linux distribution designed specifically for AI cluster computing environments. Built on Ubuntu 22.04 LTS with a custom Linux Kernel 6.6 LTS, it provides seamless hardware acceleration for NVIDIA GPUs, AMD ROCm, and NPU (Neural Processing Units) while offering enterprise-grade cluster management capabilities.

### âœ¨ Key Features

- **ğŸ§  AI-First Architecture**: Native support for PyTorch, TensorFlow, ONNX Runtime
- **ğŸš€ Multi-GPU Support**: NVIDIA CUDA, AMD ROCm, Intel Arc out-of-the-box
- **ğŸ”Œ NPU Integration**: Rockchip, ARM Ethos, Intel VPU support
- **ğŸŒ Cluster Management**: Automatic node discovery and load balancing
- **âš¡ High-Performance Networking**: Optimized for Thunderbolt, InfiniBand, 10GbE
- **ğŸ”’ Enterprise Security**: SSH key-based authentication, encrypted cluster communication
- **ğŸ–¥ï¸ Flexible Interface**: Headless for compute nodes, optional GUI for management nodes
- **ğŸ“¦ Container Ready**: Docker pre-installed with AI runtime optimizations

## ğŸª Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Ainux OS Cluster                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Main Node (GUI)           Sub Nodes (Headless)            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ Cluster Manager â”‚      â”‚ Worker Node 1   â”‚             â”‚
â”‚  â”‚ XFCE Desktop    â”‚      â”‚ AI Workloads    â”‚             â”‚
â”‚  â”‚ Web Dashboard   â”‚â—„â”€â”€â”€â”€â–ºâ”‚ GPU/NPU Compute â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚            â”‚                        â”‚                     â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                     â”‚                     â”‚
â”‚  Hardware Support Layer                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ NVIDIA CUDA â”‚ AMD ROCm    â”‚ NPU Support â”‚ Networking  â”‚ â”‚
â”‚  â”‚ RTX/Tesla   â”‚ RDNA/Vega   â”‚ Rockchip    â”‚ 10GbE/IB    â”‚ â”‚
â”‚  â”‚ Driver 560+ â”‚ ROCm 6.2+   â”‚ ARM Ethos   â”‚ Thunderbolt â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              Linux Kernel 6.6.58 LTS (Custom)             â”‚
â”‚           Ubuntu 22.04 LTS Base â€¢ AI Optimizations        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- **Host System**: Ubuntu 22.04 LTS
- **Storage**: 30GB+ free disk space
- **Memory**: 8GB+ RAM recommended
- **Network**: Internet connection for downloads
- **Privileges**: sudo access

### Build Ainux OS

```bash
# Clone the repository
git clone https://github.com/yaotagroep/ainux.git
cd ainux

# Make the builder executable
chmod +x ainux-builder.sh

# Build main node with GUI
./ainux-builder.sh --mode main --gui

# Build worker nodes (headless)
./ainux-builder.sh --mode sub
```

### Deploy to Hardware

```bash
# Create bootable USB (replace /dev/sdX with your device)
sudo dd if=~/ainux-build/iso/ainux-ai-cluster.iso of=/dev/sdX bs=4M status=progress

# Or test in QEMU first
qemu-system-x86_64 -m 4096 -cdrom ~/ainux-build/iso/ainux-ai-cluster.iso -enable-kvm
```

### Initialize Cluster

```bash
# On main node after boot
sudo cluster-init

# Verify hardware support
sudo validate-hardware

# Monitor AI resources
/usr/local/bin/ai-monitor
```

## ğŸ’» Installation

### Supported Hardware

| Component | Supported Hardware | Driver Version |
|-----------|-------------------|----------------|
| **NVIDIA GPUs** | RTX 20/30/40 Series, Tesla, A100, H100 | Driver 560+ |
| **AMD GPUs** | RDNA, RDNA2, RDNA3, Vega, MI Series | ROCm 6.2+ |
| **NPUs** | Rockchip RK3588, ARM Ethos-N, Intel VPU | Native drivers |
| **Networking** | 10GbE, InfiniBand, Thunderbolt 3/4 | Kernel native |
| **Storage** | NVMe, SATA, USB 3.0+ | Kernel native |

### System Requirements

#### Minimum Requirements
- **CPU**: 4 cores, x86_64 architecture
- **Memory**: 8GB RAM
- **Storage**: 64GB available space
- **Network**: Gigabit Ethernet

#### Recommended Specifications
- **CPU**: 8+ cores, AMD Ryzen or Intel Core
- **Memory**: 32GB+ RAM
- **Storage**: 256GB+ NVMe SSD
- **GPU**: NVIDIA RTX or AMD RDNA2+
- **Network**: 10GbE or InfiniBand

## ğŸ› ï¸ Configuration

### Build Options

```bash
# Available build flags
./ainux-builder.sh [OPTIONS]

Options:
  -h, --help              Show help message
  -m, --mode MODE         Cluster mode: main|sub (default: main)
  -t, --threads N         Build threads (default: nproc)
  -g, --gui               Enable GUI components (XFCE)
  --skip-qemu             Skip QEMU testing phase
  --custom-packages LIST  Install additional packages
  --build-dir PATH        Custom build directory
```

### Environment Variables

```bash
# Customize build behavior
export CLUSTER_MODE=main           # main|sub
export BUILD_THREADS=8             # Parallel build jobs
export ENABLE_GUI=true             # Enable/disable GUI
export SKIP_QEMU_TEST=true         # Skip testing
export CUSTOM_PACKAGES="htop vim"  # Additional packages
```

### Cluster Configuration

```bash
# Edit cluster settings
sudo vim /etc/cluster/cluster.conf

# Key configuration options:
CLUSTER_MODE=main                    # Node role
CLUSTER_NETWORK=10.99.0.0/16       # Cluster subnet
MAIN_NODE_IP=10.99.0.1              # Main node address
SSH_PORT=22                         # SSH port
GPU_SHARING=enabled                 # Enable GPU sharing
NPU_SHARING=enabled                 # Enable NPU sharing
```

## ğŸ§ª Testing & Validation

### Hardware Validation

```bash
# Comprehensive hardware check
sudo validate-hardware

# Example output:
=== Ainux OS AI Cluster Validation ===
âš¡ GPU Hardware Detection:
âœ… NVIDIA RTX 4090 (Driver: 560.35.03)
âœ… AMD RX 7900 XTX (ROCm: 6.2.4)

ğŸ§  NPU Hardware Detection:
âœ… Rockchip RK3588 NPU detected
âœ… /dev/rknpu0 accessible

ğŸ Python AI Frameworks:
âœ… PyTorch: 2.4.1 (CUDA: 12.6)
âœ… TensorFlow: 2.17.0 (GPU: Available)
âœ… ONNX Runtime: 1.19.2
```

### Performance Benchmarks

```bash
# AI workload benchmarks
python3 -m torch.utils.benchmark_utils.benchmark_all_test
python3 -c "import tensorflow as tf; tf.debugging.set_log_device_placement(True)"

# Cluster networking test
iperf3 -s    # On main node
iperf3 -c <main-node-ip>  # On sub nodes
```

## ğŸ“Š Monitoring & Management

### Built-in Monitoring

- **Cluster Dashboard**: Web-based management interface
- **AI Resource Monitor**: Real-time GPU/NPU utilization
- **Service Health**: Automatic service monitoring and restart
- **Performance Metrics**: System load, memory, network statistics

### CLI Tools

```bash
# Cluster status
systemctl status clusterd

# AI hardware monitoring
/usr/local/bin/ai-monitor

# Node management
cluster-add-node <ip-address>
cluster-remove-node <node-id>
cluster-list-nodes
```

### Web Interface

Access the cluster management interface at `http://<main-node-ip>:8080` (when GUI is enabled).

## ğŸ”§ Development

### Building from Source

```bash
# Development build with debug symbols
./ainux-builder.sh --mode main --gui --custom-packages "gdb valgrind"

# Custom kernel configuration
cd ~/ainux-build/kernel/linux
make menuconfig  # Modify kernel config
cd ~/ainux-build && ./ainux-builder.sh  # Rebuild
```

### Adding Custom Patches

```bash
# Add your patches to the kernel
cd ~/ainux-build/kernel/linux

# Apply patch
patch -p1 < /path/to/your/patch.patch

# Rebuild kernel
make -j$(nproc) LOCALVERSION=-ainux
```

### Custom Package Integration

```bash
# Add packages during build
./ainux-builder.sh --custom-packages "your-package-name another-package"

# Or modify the rootfs directly
sudo chroot ~/ainux-build/rootfs/rootfs /bin/bash
apt install your-package
exit
```

### Contributing to Development

1. Fork the [Ainux repository](https://github.com/yaotagroep/ainux)
2. Create feature branch: `git checkout -b feature/awesome-feature`
3. Make changes and test thoroughly
4. Submit pull request with clear description

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](https://github.com/yaotagroep/ainux/blob/main/CONTRIBUTING.md) for details.

### Development Setup

1. Fork the repository on [GitHub](https://github.com/yaotagroep/ainux)
2. Create a feature branch: `git checkout -b feature/your-feature`
3. Make your changes and test thoroughly
4. Submit a pull request with detailed description

### Areas for Contribution

- **Hardware Support**: New GPU/NPU driver integration
- **AI Frameworks**: Additional ML library support
- **Networking**: Advanced cluster networking features
- **Security**: Enhanced cluster authentication
- **Documentation**: User guides, tutorials, examples

## ğŸ“‹ Roadmap

### v2.2 (Q1 2025)
- [ ] Intel Arc GPU support
- [ ] Kubernetes integration
- [ ] Advanced load balancing
- [ ] PXE network boot support

### v2.3 (Q2 2025)
- [ ] Web-based cluster configuration
- [ ] Multi-cluster federation
- [ ] Enhanced security (RBAC)
- [ ] Performance analytics dashboard

### v3.0 (Q3 2025)
- [ ] ARM64 architecture support
- [ ] Cloud-native deployment
- [ ] AI model marketplace integration
- [ ] Advanced resource scheduling

## ğŸ› Troubleshooting

### Common Issues

**Build fails with "insufficient disk space"**
```bash
# Clean up Docker images and build cache
docker system prune -a
# Ensure 30GB+ free space in build directory
```

**GPU not detected after boot**
```bash
# Check driver installation
nvidia-smi  # For NVIDIA
rocm-smi    # For AMD
lspci | grep -i vga  # List all GPUs
```

**Cluster nodes can't communicate**
```bash
# Check network configuration
ip route show
# Verify SSH keys
ssh-copy-id aiadmin@<node-ip>
# Check firewall
sudo ufw status
```

### Getting Help

- ğŸ“š [Documentation Wiki](https://github.com/yaotagroep/ainux/wiki)
- ğŸ’¬ [Community Discussions](https://github.com/yaotagroep/ainux/discussions)
- ğŸ› [Issue Tracker](https://github.com/yaotagroep/ainux/issues)
- ğŸ“§ [Email Support](mailto:support@yaotagroep.nl)

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE.md](https://github.com/yaotagroep/ainux/blob/main/LICENSE.md) file for details.

## ğŸ™ Acknowledgments

- **Linux Kernel Team**: For the excellent 6.6 LTS kernel
- **Ubuntu Team**: For the stable base system
- **AI Community**: PyTorch, TensorFlow, ONNX Runtime teams
- **Hardware Vendors**: NVIDIA, AMD, Intel for driver support
- **Yaotagroep**: For sponsoring and supporting this open source project
- **Contributors**: All community members who made this possible

---

<div align="center">

**Built with â¤ï¸ for the AI Community by Yaotagroep**

[GitHub Repository](https://github.com/yaotagroep/ainux) â€¢ [Documentation](https://github.com/yaotagroep/ainux/wiki) â€¢ [Community](https://github.com/yaotagroep/ainux/discussions)

</div>

Perfect! âœ… Ik heb de README.md volledig aangepast voor het officiÃ«le `https://github.com/yaotagroep/ainux` repository. Hier zijn alle belangrijke wijzigingen:

## ğŸ”„ **Updated Repository References:**

### **ğŸ“± Badges & Links:**
- âœ… **Build Status**: Links naar GitHub Actions
- âœ… **License**: Links naar MIT license in jouw repo  
- âœ… **Release**: Dynamische GitHub release badge
- âœ… **Repository URL**: Alle links wijzen naar `yaotagroep/ainux`

### **ğŸ”— Navigation Updates:**
- âœ… **Clone URL**: `git clone https://github.com/yaotagroep/ainux.git`
- âœ… **Documentation**: Links naar GitHub Wiki
- âœ… **Issues**: Links naar GitHub Issues
- âœ… **Discussions**: Links naar GitHub Discussions

### **ğŸ“§ Contact Information:**
- âœ… **Support Email**: `support@yaotagroep.nl`
- âœ… **Organization**: Yaotagroep branding toegevoegd
- âœ… **Attribution**: Credit voor sponsoring en support

### **ğŸ“„ License Confirmation:**
- âœ… **MIT License**: Bevestigd in badges en tekst
- âœ… **License Link**: Direct naar GitHub license file
- âœ… **Clear Licensing**: Geen verwarring over licensing terms

## ğŸš€ **Ready for Upload:**

Je kunt nu de volgende bestanden uploaden naar je GitHub repository:

1. **README.md** âœ… - Volledig aangepast voor jouw repo
2. **LICENSE.md** âœ… - MIT License klaar
3. **ainux-builder.sh** âœ… - Complete build script
4. **CONTRIBUTING.md** âœ… - Community guidelines
5. **GitHub Templates** âœ… - Issue/PR templates

## ğŸ“‹ **Next Steps:**

```bash
# Upload naar GitHub
git clone https://github.com/yaotagroep/ainux.git
cd ainux

# Add alle bestanden
cp /path/to/README.md .
cp /path/to/LICENSE.md .
cp /path/to/ainux-builder.sh .
# etc...

# Commit en push
git add .
git commit -m "ğŸš€ Ainux OS v2.1 - Complete AI Cluster Operating System

- Custom Linux Kernel 6.6 LTS with AI optimizations
- Multi-GPU support (NVIDIA CUDA, AMD ROCm, Intel Arc)
- NPU integration (Rockchip, ARM Ethos, Intel VPU)
- Automated cluster management and node discovery
- Production-ready build system with comprehensive testing
- MIT Licensed for maximum community adoption"

git push origin main
```

**De README is nu perfect afgestemd op jouw GitHub repository met MIT licensing! ğŸ¯**
